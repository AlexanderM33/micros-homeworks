# Домашнее задание к занятию «Микросервисы: подходы»

Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- облачная система;
- система контроля версий Git;
- репозиторий на каждый сервис;
- запуск сборки по событию из системы контроля версий;
- запуск сборки по кнопке с указанием параметров;
- возможность привязать настройки к каждой сборке;
- возможность создания шаблонов для различных конфигураций сборок;
- возможность безопасного хранения секретных данных (пароли, ключи доступа);
- несколько конфигураций для сборки из одного репозитория;
- кастомные шаги при сборке;
- собственные докер-образы для сборки проектов;
- возможность развернуть агентов сборки на собственных серверах;
- возможность параллельного запуска нескольких сборок;
- возможность параллельного запуска тестов.

Обоснуйте свой выбор.

Ну курсе Нетологии мы изучаем инструменты DevOps для CICD - Gitlab, TeamCity, Jenkins. Gitlab — полноценная система, в которой есть все тремуемые инструменты.
Он дает возможность выполнять совместную разработку силами нескольких команд, применять обновления кода и откатывать изменения, если это необходимо.
Gitlab это самостоятельная локальная среда, в которой разработчики могут легко работать, управление исходным кодом, которое позволяет отслеживать текущую историю изменений, разрешать конфликты и легко объединять ветви.
Непрерывная интеграция (CI) обеспечивает автоматизированный конвейер для компиляции, тестирования и проверки сборок программного обеспечения.
В Gitlab реализовано автоматическое обнаружение секретов и тестирование безопасности, обеспечивающее защищенность кодовой базы. Отслеживание времени, аналитика производительности и интеграция с Jira или Trello помогают команде оставаться на связи.
То есть запрашиваемый функционал реализован в Gitlab, на нем и остановимся.

## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор логов в центральное хранилище со всех хостов, обслуживающих систему;
- минимальные требования к приложениям, сбор логов из stdout;
- гарантированная доставка логов до центрального хранилища;
- обеспечение поиска и фильтрации по записям логов;
- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- возможность дать ссылку на сохранённый поиск по записям логов.

Обоснуйте свой выбор.

В качестве решения для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре можно использовать один из самых популярных стеков – ЕFK.
Он стостоит из Elasticsearch, Logstash, 

Elasticsearch

Настоящее «сердце» ELK stack – это Elasticsearch. Elasticsearch разработан с учетом распределенной архитектуры, позволяющей легко масштабировать систему на много узлов для обработки больших объемов данных и обеспечивает высокую доступность; инструмент спроектирован для работы в реальном времени для оперативного обновления данных и получения результатов запросов без значительных задержек.

Logstash
Это инструмент для сбора, преобразования и обработки данных из разных источников. Logstash собирает данные из разных источников: лог-файлы, потоки данных, базы данных, метрики системы, системные события и многие другие. Он поддерживает много входных плагинов для разных источников; После сбора данных Logstash может выполнять различные операции над ними -  это фильтрация, структурирование, нормализация и обогащение для дальнейшего анализа. Logstash поддерживает большое количество исходных плагинов для отправки обработанных данных в различные системы и хранилища, включая Elasticsearch, Apache Kafka, Amazon S3 и многие другие. 

Kibana
Это инструмент для рендеринга и анализа данных. Он используется для создания графиков, дашбордов и отчетов на основе данных, хранящихся в Elasticsearch. Kibana позволяет пользователям интерактивно визуализировать и анализировать данные, делать запросы и получать визуальные инсайты.
Kibana дает возможность создавать различные типы визуализаций: линейные графики, столбчатые диаграммы, колеса подписей, графики рассеяния и другие. Kibana поддерживает создание карт и географических визуализаций для анализа информации, содержащей геоданные. Инструмент поддерживает систему ролей, позволяющую администраторам контролировать доступ к функциональности и данным.

Преимущества и недостатки ELK stack

Плюсы:
- все компоненты стека — открытые программы, поэтому можно бесплатно их использовать и адаптировать под свои нужды;
- ELK стек легко масштабируется, что позволяет добавлять новые узлы для обработки большего объема данных;
- ELK stack поддерживает обработку данных в реальном времени, что позволяет выявлять проблемы и анализировать события немедленно;
- стек можно масштабировать горизонтально, чтобы соответствовать растущим объемам данных и требованиям пользователей;
- ELK stack можно настроить в соответствии с различными случаями использования, от ИТ-операций и аналитики безопасности до маркетинговых исследований.

Минусы:
- настройка и развертывание ELK stack достаточно сложная;
- набор программных продуктов требует больших объемов вычислительных ресурсов и памяти для эффективной работы с большими объемами данных;
- для максимальной пользы от стека ELK нужно иметь навыки в анализе данных и разработке дашбордов;




## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор метрик со всех хостов, обслуживающих систему;
- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- сбор метрик, специфичных для каждого сервиса;
- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.

Обоснуйте свой выбор.


Для мониторинга можно использовать Prometheus + Grafana.
Prometheus получает метрики из разных сервисов и собирает их в одном месте. Grafana — отображает данные из Prometheus в виде графиков и диаграмм, организованных в дашборды.
Также используется Node exporter — приложение, собирающее метрики операционной системы и предоставляющее к ним доступ по HTTP. Prometheus собирает данные с одного или нескольких экземпляров Node Exporter.


## Задача 4: Логи * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, пишут логи в stdout. 

Добавить в систему сервисы для сбора логов Vector + ElasticSearch + Kibana со всех сервисов, обеспечивающих работу API.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Kibana.
Логин в Kibana должен быть admin, пароль qwerty123456.


## Задача 5: Мониторинг * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, предоставляют набор метрик в формате prometheus:

- сервис security по адресу /metrics,
- сервис uploader по адресу /metrics,
- сервис storage (minio) по адресу /minio/v2/metrics/cluster.

Добавить в систему сервисы для сбора метрик (Prometheus и Grafana) со всех сервисов, обеспечивающих работу API.
Построить в Graphana dashboard, показывающий распределение запросов по сервисам.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Grafana с настроенным Dashboard.
Логин в Grafana должен быть admin, пароль qwerty123456.

---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
